{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#This is not my Code. ChatGPT generates this one. My Goal is to understand what every step is trying to achieve. That's why I'm commenting \"everything\".",
   "id": "a0f7e6ba4d758876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Load TrainData and TestData and each label into their variables. \n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  "
   ],
   "id": "d45d182a9a88df2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0 #Converting everything to Float and normalizing to [0,1] White to Black \n",
    "x_test  = x_test.astype(\"float32\") / 255.0\n",
    "# CNN expects (H, W, C)\n",
    "x_train = np.expand_dims(x_train, -1) #Expands the array by one position at the end for grayscale\n",
    "x_test  = np.expand_dims(x_test, -1)"
   ],
   "id": "3564e81e3f8ccb2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#A Keras Layer block that pipelines randomRotation and RandomTranslation for every picture everytime it gets called.\n",
    "#The Goal is that the model does train on a slightly different version of the same picture, to generalize more and reduce Overfitting. \n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation(0.08),\n",
    "    tf.keras.layers.RandomTranslation(0.05, 0.05),\n",
    "], name=\"augment\")"
   ],
   "id": "7f4b45e73585973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T11:44:05.340797Z",
     "start_time": "2025-09-11T11:44:05.019397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Definition\n",
    "inputs = tf.keras.Input(shape=(28, 28, 1)) #Parameter that each picture has to fulfill\n",
    "x = data_augmentation(inputs) #use the Keras Layer block from above\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x) #Convolution 2D Layer with 32 filters and 3x3 Kernel. ReLu for non-linear relation. Output 26x26x32 Tensor. \n",
    "x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x) #Again but now each Layer combined. Output 24x24x32 Tensor.\n",
    "x = tf.keras.layers.MaxPooling2D()(x) #Iterates via 2x2-Block through every Feature Map and takes the highest number. Reduces every Layer to 12x12x32. -> less processing load\n",
    "x = tf.keras.layers.Dropout(0.25)(x) #Randomly sets 25% to Zero. Unchanged Data(75%) gets raised by 1.333. -> reduces Overfitting. Can't use the same Neurons every time.  \n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x) #Output 10x10x64 Tensor. \n",
    "x = tf.keras.layers.Conv2D(64, 3, activation=\"relu\")(x) #Output 8x8x64 Tensor. \n",
    "x = tf.keras.layers.MaxPooling2D()(x) #Output 4x4x64 Tensor\n",
    "x = tf.keras.layers.Dropout(0.25)(x) #Again to reduce Overfitting.\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x) # 4x4x64 = Vector with 1024 Features. From 3D-Tensor to 1D-Tensor.\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x) #Out of 1024 Features calculate 128 super features that are more precise. More than 128 Neurons might cause overfitting, less might lose important information\n",
    "x = tf.keras.layers.Dropout(0.5)(x) #To reduce Overfitting, deactivate half of all the neurons and multiply the others by 2 = 1 / (1-0.5)\n",
    "outputs = tf.keras.layers.Dense(10, activation=\"softmax\")(x) #10 Features because we have numbers from 0-9. softmax because we want probabilities.\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) #Build a Model that starts at inputs and ends at outputs\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3), #Gradient-Descent-Algorythm(Adam), 0.001 Starting Learning rate, How big are the steps to correct a failure\n",
    "    loss=\"sparse_categorical_crossentropy\", #sparse to reduce memory usage, calculate the loss\n",
    "    metrics=[\"accuracy\"] #Tells me how accurate my model is during training\n",
    ")\n",
    "model.summary() #Shows me the details of my model"
   ],
   "id": "9ae5de83ecdf9dd0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m inputs = \u001B[43mtf\u001B[49m.keras.Input(shape=(\u001B[32m28\u001B[39m, \u001B[32m28\u001B[39m, \u001B[32m1\u001B[39m)) \u001B[38;5;66;03m#Parameter that each picture has to fulfill\u001B[39;00m\n\u001B[32m      2\u001B[39m x = data_augmentation(inputs) \u001B[38;5;66;03m#use the Keras Layer block from above\u001B[39;00m\n\u001B[32m      3\u001B[39m x = tf.keras.layers.Conv2D(\u001B[32m32\u001B[39m, \u001B[32m3\u001B[39m, activation=\u001B[33m\"\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m\"\u001B[39m)(x) \u001B[38;5;66;03m#Convolution 2D Layer with 32 filters and 3x3 Kernel. ReLu for non-linear relation. Output 26x26x32 Tensor. \u001B[39;00m\n",
      "\u001B[31mNameError\u001B[39m: name 'tf' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True), #if, for example, the validation loss does not improve over three cycles, training stops. restore_best_weights takes the best weights not the last\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=2, factor=0.5) #if, for example, the validation loss does not improve for two cycles, learn rate gets halved.\n",
    "]\n",
    "history = model.fit( #train the model\n",
    "    x_train, y_train, #training data\n",
    "    validation_split=0.1, #use 10% as validation data\n",
    "    epochs=15, #15 cycles\n",
    "    batch_size=128, #128 pictures \n",
    "    callbacks=callbacks, #uses the callback code from above\n",
    "    verbose=2\n",
    ")"
   ],
   "id": "38a0fbfd0c6902f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0) #use the test data to check how accurate is my model\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "y_pred = model.predict(x_test, verbose=0).argmax(axis=1) #probability for each Number, argmax takes the highest probability. y_pred array for each number in every picture.\n",
    "print(classification_report(y_test, y_pred)) #compares each label with y_pred and tells me which numbers my model identifies better than others\n"
   ],
   "id": "d80af91e580ce3dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Full display of my model with y_test and y_pred as Data to see where my model lacks\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix (MNIST)\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ],
   "id": "645127f887b8df1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.save(\"mnist_cnn\")",
   "id": "280b79221646964"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
